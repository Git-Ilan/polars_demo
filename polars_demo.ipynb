{
 "cells": [
  {
   "cell_type": "raw",
   "id": "599da3b5",
   "metadata": {},
   "source": [
    "---\n",
    "title: Intro 2 Polars\n",
    "execute:\n",
    "  eval: false\n",
    "  warning: true\n",
    "  error: true\n",
    "  keep-ipynb: true\n",
    "  cache: true\n",
    "pdf-engine: lualatex\n",
    "html:\n",
    "  code-tools: false\n",
    "  fold-code: false\n",
    "  author: Jonathan D. Rosenblatt\n",
    "  data: 02-27-2023\n",
    "  toc: false\n",
    "  number-sections: true\n",
    "  number-depth: 3\n",
    "  embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5058a8fa",
   "metadata": {},
   "source": [
    "# Background {#sec-background}\n",
    "\n",
    "\n",
    "## Ritchie Vink, Rust, Apache Arrow and Covid\n",
    "\n",
    "[Here](https://www.ritchievink.com/blog/2021/02/28/i-wrote-one-of-the-fastest-dataframe-libraries/) is the story, by the creator of Polars.\n",
    "\n",
    "\n",
    "## Who Can Benefit from Polars?\n",
    "\n",
    "- Researcher (DS, Analyst, Statistician, etc):\n",
    "  - Working on their local machine. \n",
    "  - Working on a cloud machine (SageMaker, EC2).\n",
    "- Production system:\n",
    "  - Running on a dedicated server. \n",
    "  - Running on \"serverless\" (e.g. AWS Lambda, Google Cloud Functions).\n",
    "\n",
    "## The DataFrame Landscape\n",
    "\n",
    "Initially there were R's `data.frame`. \n",
    "R has evolved, and it now offers `tibble`s and `data.table`s.\n",
    "Python had only `Pandas` for years. \n",
    "Then the Python ecosystem exploded, and now we have:\n",
    "\n",
    "-  [Pandas](https://Pandas.pydata.org/): The original Python dataframe module. Build by Wes McKinney, on top of numpy.\n",
    "-  [Polars](https://www.pola.rs/): A new dataframe module, build by Ritchie Vink, on top of Rust and Apache Arrow.\n",
    "-  [datatable](https://datatable.readthedocs.io/en/latest/): An attempt to recreate R's [data.table](https://github.com/Rdatatable/data.table) API and (crazy) speed in Python. \n",
    "-  [Dask](https://www.dask.org/): A distributed computing engine for Python, with support for distributing data over multiple processes running Pandas (or numpy, Polars, etc).\n",
    "-  [Vaex](https://vaex.io/): A high performance Python library for lazy Out-of-Core DataFrames (similar to dask, but with a different API).\n",
    "-  [Modin](https://github.com/modin-project/modin): A drop-in distributed  replacement for Pandas, built on top of [Ray](https://www.ray.io/). \n",
    "-  [DuckDB](https://duckdb.org/): An embeddable SQL OLAP database management system. These are dataframe that are stored on disk, compute on a single process, and queried with SQL or pythonic API.\n",
    "- [Daft](https://www.getdaft.io/): A distributed dataframe library built for \"Complex Data\" (data that doesn't usually fit in a SQL table such as images, videos, documents etc). \n",
    "-  [Fugue](https://fugue-tutorials.readthedocs.io/): A dataframe library that allows you to write SQL-like code, and execute it on different backends (e.g. Spark, Dask, Pandas, Polars, etc).\n",
    "-  [pySpark](https://spark.apache.org/docs/latest/api/python/index.html): The Python API for Spark. Spark is a distributed computing engine, with support for distributing data over multiple processes running Pandas (or numpy, Polars, etc).\n",
    "-  [CUDF](https://github.com/rapidsai/cudf): A GPU accelerated dataframe library, build on top of Apache Arrow.\n",
    "\n",
    "\n",
    "\n",
    "See [here](https://pola-rs.github.io/Polars-book/user-guide/misc/alternatives/) and [here](https://www.getdaft.io/projects/docs/en/latest/dataframe_comparison.html) for more details. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Motivation {#sec-motivation}\n",
    "\n",
    "Each of the following, alone(!), is amazing.\n",
    "\n",
    "1. Small memory footprint.\n",
    "1. Native dtypes: missing, strings.\n",
    "2. Lazy evaluation allows query Planning.\n",
    "3. Streaming engine: No need to load entire dataset into memory.\n",
    "4. Out of the box parallelism: Fast and informative messages for debugging.\n",
    "5. Strict typing: This means the dtype of output is defined by the operation and not bu the input. This is both safer, and allows static analysis.\n",
    "\n",
    "\n",
    "## Setting Up the Environment\n",
    "\n",
    "At this point you may want to create and activate a [venv](https://realpython.com/python-virtual-environments-a-primer/) for this project. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64bbb2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip\n",
    "# %pip install --upgrade Polars\n",
    "# %pip install --upgrade pyarrow\n",
    "# %pip install --upgrade Pandas\n",
    "# %pip install --upgrade plotly\n",
    "# %pip freeze > requirements.txt\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "Polars-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Polars-version\n",
    "%pip show Polars # check you Polars version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Pandas-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Pandas-version\n",
    "%pip show Pandas # check you Polars version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "preliminaries",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: preliminaries\n",
    "\n",
    "import polars as pl\n",
    "pl.Config(fmt_str_lengths=50)\n",
    "import polars.selectors as cs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import plotly.express as px\n",
    "import string\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Following two lines only required to view plotly when rendering from VScode. \n",
    "import plotly.io as pio\n",
    "# pio.renderers.default = \"plotly_mimetype+notebook_connected+notebook\"\n",
    "pio.renderers.default = \"plotly_mimetype+notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20170192",
   "metadata": {},
   "source": [
    "## Memory Footprint\n",
    "\n",
    "### Memory Footprint of Storage\n",
    "\n",
    "Comparing Polars to Pandas- the memory footprint of a series of strings. \n",
    "\n",
    "Polars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a19cbcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = pl.Series(list(string.ascii_letters))\n",
    "\n",
    "n = int(10e6)\n",
    "letter1 = letters.sample(n,with_replacement=True)\n",
    "letter1.estimated_size(unit='gb') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e27939",
   "metadata": {},
   "source": [
    "Pandas before Pandas 2.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbc6a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas with Ver 1.x backend\n",
    "letter1_Pandas = letter1.to_pandas(use_pyarrow_extension_array=False) \n",
    "letter1_Pandas.memory_usage(deep=True, index=False) / 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200522d3",
   "metadata": {},
   "source": [
    "Pandas after Pandas 2.0, with the Pyarrow backend (Apr 2023)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba5151fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "letter1_Pandas = letter1.to_pandas(use_pyarrow_extension_array=True) \n",
    "letter1_Pandas.memory_usage(deep=True, index=False) / 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce75949",
   "metadata": {},
   "source": [
    "### Operating From Disk to Disk\n",
    "\n",
    "What if my data does not fit into RAM? \n",
    "Turns out you manifest a lazy frame into disk, instead of RAM, thus avoiding the need to load the entire dataset into memory. \n",
    "Alas, the function that does so, [sink_parquet()](https://pola-rs.github.io/Polars/py-Polars/html/reference/lazyframe/api/Polars.LazyFrame.sink_parquet.html), has currently limited functionality. \n",
    "It is certainly worth keeping an eye on this function, as it matures.\n",
    "\n",
    "::: {.callout-note}\n",
    "Although the potential of `sink_parquet()` is amazing, I find that it currently does not support complicated queries. \n",
    ":::\n",
    "\n",
    "\n",
    "## Lazy Frames and Query Planning\n",
    "\n",
    "Consider a sort operation that follows a filter operation. \n",
    "Ideally, filter precedes the sort, but we did not ensure this... \n",
    "We now demonstrate that Polars' query planner will do it for you. \n",
    "En passant, we see Polars is more efficient also without the query planner.\n",
    "\n",
    "\n",
    "Polars' Eager evaluation in the **wrong** order. \n",
    "Sort then filter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd450f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 2 -r 2 letter1.sort().filter(letter1.is_in(['a','b','c']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5468682",
   "metadata": {},
   "source": [
    "Polars' Eager evaluation in the **right** order. \n",
    "Filter then sort.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c944b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 2 -r 2 letter1.filter(letter1.is_in(['a','b','c'])).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "398cdbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "latter1_lazy = letter1.alias('letters').to_frame().lazy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb5dea6",
   "metadata": {},
   "source": [
    "Polars' Lazy evaluation in the **wrong** order; **without** query planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4b8e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 2 -r 2 latter1_lazy.sort(by='letters').filter(pl.col('letters').is_in(['a','b','c'])).collect(no_optimization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ced91a",
   "metadata": {},
   "source": [
    "Polars' Lazy evaluation in the **wrong** order; **with** query planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f109f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 2 -r 2 latter1_lazy.sort(by='letters').filter(pl.col('letters').is_in(['a','b','c'])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90c0e39",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    "1. A lazy evaluation was triggered when `df.lazy()` converted the Polars DataFrame to a Polars LazyFrame.\n",
    "2. The query planner worked: The Lazy evaluation in the wrong order timed as much as an eager evaluation in the right order; even when accounting for the overhead of converting the frame from eager to lazy.\n",
    "\n",
    "Now compare to Pandas...\n",
    "\n",
    "Pandas' eager evaluation in the **wrong** order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cd28935",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n1 -r1 letter1_Pandas.sort_values().loc[lambda x: x.isin(['a','b','c'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6bd614",
   "metadata": {},
   "source": [
    "Pandas eager evaluation in the **right** order: Filter then sort.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da535831",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n1 -r1 letter1_Pandas.loc[lambda x: x.isin(['a','b','c'])].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9966b826",
   "metadata": {},
   "source": [
    "Pandas without lambda functions syntax; looks slightly better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f4f6411",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 2 -r 2 letter1_Pandas.loc[letter1_Pandas.isin(['a','b','c'])].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdffe7ba",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    "1. Query planning works!\n",
    "2. Pandas has dramatically improved since <2.0.0. \n",
    "3. Lambda functions are always slow (both Pandas and Polars).\n",
    "\n",
    "\n",
    "## Optimized for Within-Column Operations\n",
    "\n",
    "Polars seamlessly parallelizes over columns (also within, when possible). \n",
    "As the number of columns in the data grows, we would expect fixed runtime until all cores are used, and then linear scaling. \n",
    "The following code demonstrates this idea, using a simple sum-within-column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3afc28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mac users with Apple silicon (M1 or M2) may also want to benchmark Apples' mlx:\n",
    "# %pip install mlx\n",
    "import mlx.core as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d207ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maker an array of floats.\n",
    "A_numpy = np.random.randn(int(1e6), 10)\n",
    "\n",
    "A_numpy = A_numpy.copy()\n",
    "A_Polars = pl.DataFrame(A_numpy)\n",
    "A_Pandas_numpy = pd.DataFrame(A_numpy)\n",
    "A_Pandas_arrow = pd.DataFrame(A_numpy, dtype=\"float32[pyarrow]\")\n",
    "# A_arrow = pa.Table.from_Pandas(A_Pandas_numpy) # no sum method\n",
    "A_mlx = mx.array(A_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0bf6c",
   "metadata": {},
   "source": [
    "Candidates currently omited:\n",
    "\n",
    "1. JAX\n",
    "2. PyTorch\n",
    "3. TensorFlow\n",
    "4. ...?\n",
    "\n",
    "\n",
    "\n",
    "### Summing Over Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3354c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 4 -r 2 A_numpy.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02ad802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_numpy.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87c04ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 4 -r 2 A_Polars.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7b7504",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_Polars.sum().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78f388f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 4 -r 2 A_mlx.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df989429",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_mlx.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570b7e8",
   "metadata": {},
   "source": [
    "### 50 Shades of Pandas\n",
    "\n",
    "Pandas with numpy backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71de1d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 4 -r 2 A_Pandas_numpy.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cc90b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_Pandas_numpy.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389790ee",
   "metadata": {},
   "source": [
    "Pandas with arrow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a3b089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 4 -r 2 A_Pandas_arrow.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d0277a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_Pandas_arrow.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8f8e6f",
   "metadata": {},
   "source": [
    "Pandas with numpy backend, converted to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b999dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 4 -r 2 A_Pandas_numpy.values.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b8f67d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_Pandas_numpy.values.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d84b896",
   "metadata": {},
   "source": [
    "Pandas with arrow backend, converted to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11271399",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 4 -r 2 A_Pandas_arrow.values.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eabe82a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(A_Pandas_arrow.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b94da697",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_Pandas_arrow.values.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf555f6",
   "metadata": {},
   "source": [
    "Pandas to mlx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9857342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 4 -r 2 mx.array(A_Pandas_numpy.values).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e106bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx.array(A_Pandas_numpy.values).sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac3b5c0",
   "metadata": {},
   "source": [
    "### Summing Over Rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4233ae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 4 -r 2 A_numpy.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47f94765",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_numpy.sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f10dbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 4 -r 2 A_Polars.sum_horizontal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a08a119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_Polars.sum_horizontal().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3381c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 4 -r 2 A_mlx.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e41c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_mlx.sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ab21b",
   "metadata": {},
   "source": [
    "### 50 Shades of Pandas\n",
    "\n",
    "Pandas with numpy backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71b63e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 4 -r 2 A_Pandas_numpy.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8356801c",
   "metadata": {},
   "source": [
    "Pandas with arrow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8453d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 4 -r 2 A_Pandas_arrow.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17498372",
   "metadata": {},
   "source": [
    "Pandas with numpy backend, converted to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90cc2e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 4 -r 2 A_Pandas_numpy.values.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3019431",
   "metadata": {},
   "source": [
    "Pandas with arrow backend, converted to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35b5ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 4 -r 2 A_Pandas_arrow.values.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81414c41",
   "metadata": {},
   "source": [
    "Pandas to mlx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "201b5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 4 -r 2 mx.array(A_Pandas_numpy.values).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efaeb61",
   "metadata": {},
   "source": [
    "## Speed Of Import\n",
    "\n",
    "Polar's `read_X` functions are quite faster than Pandas. \n",
    "This is due to better type \"guessing\" heuristics, and easier mapping between the disk representation and memory representation of the data.\n",
    "\n",
    "We benchmark by making synthetic data, save it on disk, and reimporting it.\n",
    "\n",
    "### CSV Format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97c4b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = int(1e5)\n",
    "n_cols = 10\n",
    "data_Polars = pl.DataFrame(np.random.randn(n_rows,n_cols))\n",
    "data_Polars.write_csv('data/data.csv', include_header = False)\n",
    "f\"{os.path.getsize('data/data.csv')/1e7:.2f} MB on disk\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e052b4b7",
   "metadata": {},
   "source": [
    "Import with Pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4616b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n2 -r2 data_Pandas = pd.read_csv('data/data.csv', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98de85d",
   "metadata": {},
   "source": [
    "Import with Polars.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d20cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n2 -r2 data_Polars = pl.read_csv('data/data.csv', has_header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a544ca",
   "metadata": {},
   "source": [
    "What is the ratio of times on your machine?\n",
    "How many cores do you have?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Parquet Format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa88b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Polars.write_parquet('data/data.parquet')\n",
    "f\"{os.path.getsize('data/data.parquet')/1e7:.2f} MB on disk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03e24d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n2 -r2 data_Pandas = pd.read_parquet('data/data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ac4cc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n2 -r2 data_Polars = pl.read_parquet('data/data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a51b19e",
   "metadata": {},
   "source": [
    "### Feather (Apache IPC) Format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4d3e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Polars.write_ipc('data/data.feather')\n",
    "f\"{os.path.getsize('data/data.feather')/1e7:.2f} MB on disk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90be8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n2 -r2 data_Polars = pl.read_ipc('data/data.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d19bdbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n2 -r2 data_Pandas = pd.read_feather('data/data.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad72ddb",
   "metadata": {},
   "source": [
    "### Pickle Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "013562f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(data_Polars, open('data/data.pickle', 'wb'))\n",
    "f\"{os.path.getsize('data/data.pickle')/1e7:.2f} MB on disk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b871a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n2 -r2 data_Polars = pickle.load(open('data/data.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6190fafb",
   "metadata": {},
   "source": [
    "### Summarizing Import\n",
    "\n",
    "Things to note:\n",
    "\n",
    "1. The difference in speed is quite large between Pandas vs. Polars.\n",
    "1. When dealing with CSV's, the function `pl.read_csv` reads in parallel, and has better type guessing heuristics.\n",
    "2. The difference in speed is quite large between csv vs. parquet and feather, with feather\\<parquet\\<csv.\n",
    "1. Feather is the fastest, but larger on disk. Thus good for short-term storage, and parquet for long-term.\n",
    "1. The fact that pickle isn't the fastest surprised me; but then again, it is not optimized for data.\n",
    "\n",
    "\n",
    "\n",
    "## Speed Of Join\n",
    "\n",
    "Because Pandas is built on numpy, people see it as both an in-memory database, and a matrix/array library. With Polars, it is quite clear it is an in-memory database, and not an array processing library (despite having a `pl.dot()` function for inner products). As such, you cannot multiply two Polars dataframes, but you can certainly join then efficiently.\n",
    "\n",
    "Make some data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c9f4262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(n_rows, n_cols):\n",
    "  data = np.concatenate(\n",
    "  (\n",
    "    np.arange(n_rows)[:,np.newaxis], # index\n",
    "    np.random.randn(n_rows,n_cols), # values\n",
    "    ),\n",
    "    axis=1)\n",
    "    \n",
    "  return data\n",
    "\n",
    "\n",
    "n_rows = int(1e6)\n",
    "n_cols = 10\n",
    "data_left = make_data(n_rows, n_cols)\n",
    "data_right = make_data(n_rows, n_cols)\n",
    "\n",
    "data_left.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c86e1ed",
   "metadata": {},
   "source": [
    "### Polars Join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a34a8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_left_Polars = pl.DataFrame(data_left)\n",
    "data_right_Polars = pl.DataFrame(data_right)\n",
    "\n",
    "%timeit -n2 -r2 Polars_joined = data_left_Polars.join(data_right_Polars, on = 'column_0', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7008dbf",
   "metadata": {},
   "source": [
    "### Pandas Join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ce8c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_left_Pandas = pd.DataFrame(data_left)\n",
    "data_right_Pandas = pd.DataFrame(data_right)\n",
    "\n",
    "%timeit -n2 -r2 Pandas_joined = data_left_Pandas.merge(data_right_Pandas, on = 0, how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368717d1",
   "metadata": {},
   "source": [
    "## The NYC Taxi Dataset {#sec-nyc_taxi}\n",
    "\n",
    "Empirical demonstration:\n",
    "Load the celebrated NYC taxi dataset, filter some rides and get the mean `tip_amount` by `passenger_count`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05bba24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/NYC' # Data from https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "file_names = os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02776f09",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "`df.query()` syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c362ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "taxi_Pandas = pd.read_parquet(path)\n",
    "\n",
    "query = '''\n",
    "    passenger_count > 0 and \n",
    "    passenger_count < 5 and  \n",
    "    trip_distance >= 0 and \n",
    "    trip_distance <= 10 and \n",
    "    fare_amount >= 0 and \n",
    "    fare_amount <= 100 and \n",
    "    tip_amount >= 0 and \n",
    "    tip_amount <= 20 and \n",
    "    total_amount >= 0 and \n",
    "    total_amount <= 100\n",
    "    '''.replace('\\n', '')\n",
    "taxi_Pandas.query(query).group_by('passenger_count').agg({'tip_amount':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93fbd99",
   "metadata": {},
   "source": [
    "Well, the `df.loc[]` syntax is usually faster than the `query` syntax:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "07a7d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "taxi_Pandas = pd.read_parquet(path)\n",
    "\n",
    "ind = (\n",
    "    taxi_Pandas['passenger_count'].between(1,4) \n",
    "    & taxi_Pandas['trip_distance'].between(0,10) \n",
    "    & taxi_Pandas['fare_amount'].between(0,100) \n",
    "    & taxi_Pandas['tip_amount'].between(0,20) \n",
    "    & taxi_Pandas['total_amount'].between(0,100)\n",
    ")\n",
    "(\n",
    "    taxi_Pandas[ind]\n",
    "    .group_by('passenger_count')\n",
    "    .agg({'tip_amount':'mean'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b5ddf8",
   "metadata": {},
   "source": [
    "### Polars Lazy In Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8604693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "import pyarrow.dataset as ds\n",
    "dset = ds.dataset(\"data/NYC\", format=\"parquet\")  # define folder as Pyarrow dataset\n",
    "\n",
    "q = (\n",
    "    pl.scan_pyarrow_dataset(dset)\n",
    "    # pl.read_parquet(\"data/NYC/*.parquet\") # will now work because parquet was created with Int32, and not Int64. \n",
    "    .filter(\n",
    "        pl.col('passenger_count').is_between(1,4),\n",
    "        pl.col('trip_distance').is_between(0,10),\n",
    "        pl.col('fare_amount').is_between(0,100),\n",
    "        pl.col('tip_amount').is_between(0,20),\n",
    "        pl.col('total_amount').is_between(0,100)\n",
    "    )\n",
    "    .group_by('passenger_count')\n",
    "    .agg(\n",
    "      pl.col('tip_amount').mean().name.suffix('_mean')\n",
    "      ) \n",
    "    )\n",
    "\n",
    "q.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3c667615",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.show_graph(optimized=True) # Graphviz has to be installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f55523",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    "1. I did not use the native `pl.scan_parquet()` as it is recommended. For your purposes, you will almost always use the native readers. It is convenient to remember, however, that you can also use the PyArrow importers in the native importers fail. \n",
    "2. I only have 2 parquet files. When I run the same with more files, despite my 16GB of RAM, **Pandas will crash my python kernel**.\n",
    "3. From the query graph I see import is done in parallel, and filtering done at scanning time!\n",
    "4. \n",
    "\n",
    "\n",
    "\n",
    "### Polars Lazy From Disk\n",
    "\n",
    "::: {.callout-important}\n",
    "The following shows how to use the Polars streaming engine. \n",
    "This is arguably the biggest difference with Pandas, and other in memory dataframe libraries.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "Polars-lazy-from-disk",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Polars-lazy-from-disk\n",
    "\n",
    "q.collect(streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b38d3f",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Object Classes\n",
    "\n",
    "- **Polars Series**: Like a Pandas series. An in-memory array of data, with a name, and a dtype. \n",
    "\n",
    "- **Polars Expr**: A Polars series that is not yet computed, and that will be computed when needed.  A Polars Expression can be thought of as:\n",
    "  1. A Lazy Series: A series that is not yet computed, and that will be computed when needed.\n",
    "  2. A function: That maps a Polars series to another Polars series (possibly of length 1).\n",
    "\n",
    "- **Polars LazyFrame**: A collection of Polars Expressions. This is the Polars equivalent of a Spark DataFrame. It is lazy, thus allows query planning.\n",
    "\n",
    "- **Polars DataFrame**: A collection of Polars Series. This is the Polars equivalent of a Pandas DataFrame. It is eager, and does not allow query planning.\n",
    "  \n",
    "\n",
    "::: {.callout-warning}\n",
    "Not all methods are implemented for all classes. \n",
    "In particular, not all `pl.Dataframe` methods are implemented for `pl.LazyFrame` and vice versa. The same goes for `pl.Series` and `pl.Expr`.\n",
    "\n",
    "This is not because the developers are lazy, but because the API is still being developed, and there are fundamental differences between the classes.\n",
    "\n",
    "Think about it:\n",
    "\n",
    "1. Why do we not see a `df.height` attribute for a `pl.LazeFrame`?\n",
    "2. Why do we not see a `df.sample()` method for a `pl.LazyFrame`?\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "## Evaluation Engines\n",
    "\n",
    "Polars seemingly **2 evaluation engines**:\n",
    "\n",
    "1. **Eager**: This is the default. It is the same as Pandas. When you call a method, the method is immediately executed.\n",
    "2. **Lazy**: This is the same as Spark. When you call a method, the method is not immediately executed. Instead, a query plan is created. The query plan is then executed when you call `.collect()`.\n",
    "\n",
    "Why \"seemingly\" 2? \n",
    "Because each engine has it's own subtleties.\n",
    "For instance, the behavior of the lazy engine may depend on streaming VS non-streaming evaluation, and on the means of loading the data.\n",
    "\n",
    "1. **Streaming**: This is a special case of lazy evaluation. It is used when you have a large dataset, and you want to process it in chunks. You can then call `.collect(streaming=True)` to process the dataset in chunks. This is useful when you have a dataset that is too large to fit into memory, and you want to process it in chunks. It is also useful when you want to process a dataset in real-time, as it is being generated.\n",
    "2. **Loading**: Reading multiple parquet files using Polars native readers, may behave slightly different than reading the same files as a Pyarrow dataset (always prefer the native readers, when possible).\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "## Polars dtypes\n",
    "\n",
    "Polars has its own dtypes, call with `pl.<dtype>`; e.g. `pl.Int32`.\n",
    "A comprehensive list may be found [here](https://docs.pola.rs/py-Polars/html/reference/datatypes.html).\n",
    "\n",
    "Here are the most common. \n",
    "Note, that unlike Pandas, all are native Polars dtypes, and do not recur to Python objects. \n",
    "\n",
    "- Floats: \n",
    "  - `pl.Float64`: Arguably, the most frequently used dtype.\n",
    "- Integers: \n",
    "  - `pl.Int64`: The most frequently used integer dtype.\n",
    "- Booleans: \n",
    "  - `pl.Boolean`: As the name suggests. \n",
    "- Strings: \n",
    "  - `pl.Utf8`: The only string encoding supported by Polars. \n",
    "  - `pl.String`: Recently introduced as an alias to `pl.Utf8`.\n",
    "- Temporal: \n",
    "  - `pl.Date`: Date, without time.\n",
    "  - `pl.Datetime`: Date, with time. \n",
    "  - `pl.Time`: Time, without date.\n",
    "  - `pl.Duration`: Time difference.\n",
    "- Nulls: \n",
    "  - `pl.Null`: Polars equivalent of `None`.\n",
    "  - `np.nan`: The numpy dtype. Essentially a float, and not as a null.\n",
    "- Nested:\n",
    "  - `pl.List`: A list of items.\n",
    "  - `pl.Array`: Fixed length list. \n",
    "  - `pl.Struct`: Think of it as a dict within a frame.\n",
    "\n",
    "\n",
    "\n",
    "Things to note:\n",
    "\n",
    "-  Polars has no `Int` dtype, nor `Float`. You must specify the number of bits.\n",
    "-  Polars recently introduced `pl.String` as an alias for `pl.Utf8`. No other encodings are supported.\n",
    "-  Polars also supports `np.nan`(!), which is different than its `pl.Null` dtype. `np.nan` is a **float**, and `Null` is a None.\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "## The Polars API\n",
    "\n",
    "- You will fall in love with it!\n",
    "- Much more similar to PySpark than to Pandas. The Pandas API is simply not amenable to lazy evaluation. \n",
    "\n",
    "\n",
    "### Some Design Principles {#sec-api-principles}\n",
    "\n",
    "Here are some principles that will help you understand the API:\n",
    "\n",
    "1. All columns are created equal. There are **no indexing** columns. \n",
    "\n",
    "2. Always **remember the class** you are operating on: Is it a series, a dataframe, an expression, or a lazyframe?\n",
    "\n",
    "5. Operations on the columns of a dataframe will always be part of a **context**. Context may include:\n",
    "    1. `pl.DataFrame.select()`: This is the most common context. It is used to select columns, and to apply operations on columns.\n",
    "    2. `pl.DataFrame.with_columns()`: This is used to add columns to a dataframe.\n",
    "    3. `pl.DataFrame.group_by().agg()`: The `.agg()` context works like a `.select()` context, but it is used to apply operations on sub-groups of rows.\n",
    "    4. `pl.DataFrame.filter()`: This is used to filter rows using expressions that evaluate to Booleans.\n",
    "\n",
    "6. Two-word methods are always lower-case, and separated by underscores. E.g: `.is_in()` instead of `.isin()`; `.is_null()` instead of `.isnull()`; `.group_by()` instead of `.group_by()` (starting version 19.0.0). \n",
    "\n",
    "7. Polars was designed for operation within **columns**, not within rows. Operations within rows are the exception, and the will have a `_horizontal()` suffix. Examples: `pl.sum_horizontal()`, `pl.mean_horizontal()`, `pl.rolling_sum_horizontal()`.\n",
    "\n",
    "8. Look for `pl.Expr()` methods so you can chain operations. E.g. `pl.col('a').add(pl.col('b'))` is better than `pl.col('a') + pl.col('b')`; the former can be further chained.\n",
    "  \n",
    "\n",
    "### Some Examples of the API\n",
    "\n",
    "Here is an example to give you a little taste of what the API feels like. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "Polars-api",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Polars-api\n",
    "\n",
    "# Make some data\n",
    "polars_frame = pl.DataFrame(make_data(100,4))\n",
    "polars_frame.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326d99fd",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "What is the difference between `.head()` and `limit()`?\n",
    "For eager frames? For lazy frames?\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "Can you parse the following in your head?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7be7b542",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "  polars_frame\n",
    "  .rename({'column_0':'group'})\n",
    "  .with_columns(\n",
    "    pl.col('group').cast(pl.Int32),\n",
    "    pl.col('column_1').ge(0).alias('non-negative'),\n",
    "  )\n",
    "  .group_by('non-negative')\n",
    "  .agg(\n",
    "    pl.col('group').is_between(1,4).sum().alias('one-to-four'),\n",
    "    pl.col('^column_[0-9]$').mean().name.suffix('_mean'),\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918050d2",
   "metadata": {},
   "source": [
    "Ask yourself:\n",
    "\n",
    "- What is `polars_frame`? Is it an eager or a lazy Polars dataframe?\n",
    "- Why is `column_1_mean` when `non-negative=false` indeed non negative?\n",
    "- What is a Polars expression?\n",
    "- What is a Polars series?\n",
    "- How did I create the columns `column_1_mean`...`column_4_mean`?\n",
    "- How would you have written this in Pandas?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "Polars-api-second-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Polars-api-second-example\n",
    "\n",
    "(\n",
    "  polars_frame\n",
    "  .rename({'column_0':'group'})\n",
    "  .select(\n",
    "    pl.col('group').mod(2),\n",
    "\n",
    "    pl.mean_horizontal(\n",
    "      pl.col('^column_[0-9]$')\n",
    "    )\n",
    "    .name.suffix('_mean')\n",
    "  )\n",
    "  .filter(\n",
    "    pl.col('group').eq(1),\n",
    "    pl.col('column_1_mean').gt(0)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea7e49d",
   "metadata": {},
   "source": [
    "Try parsing the following in your head:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "72761cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "polars_frame_2 = (\n",
    "  pl.DataFrame(make_data(100,1))\n",
    "  .select(\n",
    "    pl.col('*').name.suffix('_second')\n",
    "  )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "(\n",
    "  polars_frame\n",
    "  .join(\n",
    "    polars_frame_2,\n",
    "    left_on = 'column_0',\n",
    "    right_on = 'column_0_second',\n",
    "    how = 'left',\n",
    "    validate='1:1'\n",
    "  )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3862c7f0",
   "metadata": {},
   "source": [
    "Can you parse the following in your head?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3b0d359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "polars_frame_3 = pl.DataFrame(make_data(10,1))\n",
    "\n",
    "(\n",
    "  polars_frame.lazy()\n",
    "  .select(\n",
    "    pl.col('*').name.suffix('_first')\n",
    "  )\n",
    "  .with_context(\n",
    "    polars_frame_3.lazy()\n",
    "    .select(\n",
    "      pl.col('*').name.suffix('_third')\n",
    "    ) \n",
    "  )\n",
    "  .select(\n",
    "    'column_0_first',\n",
    "\n",
    "    pl.when(\n",
    "      pl.col('column_0_first').mod(2).eq(0)\n",
    "      )\n",
    "    .then(\n",
    "      pl.lit(1)\n",
    "      )\n",
    "    .otherwise(\n",
    "      polars_frame_3\n",
    "      .select(\n",
    "        pl.last().min()\n",
    "        )\n",
    "      )\n",
    "  )\n",
    "  .collect(streaming=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42190f1e",
   "metadata": {},
   "source": [
    "## Getting Help\n",
    "\n",
    "Before we dive in, you should be aware of the following references for further help:\n",
    "\n",
    "1.  A [github page](https://github.com/pola-rs/Polars). It is particular important to subscribe to [release updates](https://github.com/pola-rs/Polars/releases). \n",
    "2.  A [user guide](https://pola-rs.github.io/Polars-book/user-guide/index.html).\n",
    "3.  A very active community on [Discord](https://discord.gg/4UfP5cfBE7).\n",
    "4.  The [API reference](https://pola-rs.github.io/Polars/py-Polars/html/reference/index.html).\n",
    "5.  A Stack-Overflow [tag](https://stackoverflow.com/questions/tagged/python-Polars).\n",
    "6.  Cheat-sheet for [Pandas users](https://www.rhosignal.com/posts/Polars-Pandas-cheatsheet/).\n",
    "\n",
    "**Warning**: Be careful of AI assistants such as Github-Copilot, TabNine, etc. \n",
    "Polars is still very new, and they may give you Pandas completions instead of Polars.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Polars Series {#sec-series}\n",
    "\n",
    "A Polars series looks a feels a lot like a Pandas series.\n",
    "You usually will try to avoid them because: (a) Your objects will usually be in frames, not in series. (b) If in frames, you will be calling `pl.Expr()` methods, and not `pl.Series()` methods. \n",
    "Getting used to Polars series, will thus give you bad intuitions when you move to Polars expressions.\n",
    "Nevertheless, it is the simples object to learn, so we start there. \n",
    "\n",
    "\n",
    "Construct a series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "make-a-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: make-a-series\n",
    "s = pl.Series(\"a\", [1, 2, 3])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af9127",
   "metadata": {},
   "source": [
    "Make Pandas series for later comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "make-a-Pandas-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: make-a-Pandas-series\n",
    "s_Pandas = pd.Series([1, 2, 3], name = \"a\")\n",
    "s_Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535e40ff",
   "metadata": {},
   "source": [
    "Notice even the printing to Jupiter is different.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "check-series-type",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: check-series-type\n",
    "type(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "check-Pandas-series-type",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: check-Pandas-series-type\n",
    "type(s_Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "check-series-dtype",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: check-series-dtype\n",
    "s.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "check-Pandas-series-dtype",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: check-Pandas-series-dtype\n",
    "s_Pandas.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02058cc5",
   "metadata": {},
   "source": [
    "Renaming a series; will be very useful when operating on dataframe columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "rename-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: rename-series\n",
    "s.alias(\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a2a842",
   "metadata": {},
   "source": [
    "Constructing a series of floats, for later use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "make-a-float-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: make-a-float-series\n",
    "f = pl.Series(\"a\", [1., 2., 3.])\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "check-float-series-dtype",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: check-float-series-dtype\n",
    "f.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1ab29",
   "metadata": {},
   "source": [
    "## Export To Other Python Objects\n",
    "\n",
    "The current section deals with exports to other python objects, **in memory**. \n",
    "See @sec-disk-export for exporting to disk.\n",
    "\n",
    "Export to Polars DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "series-to-Polars-dataframe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-to-Polars-dataframe\n",
    "s.to_frame() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e2c8f",
   "metadata": {},
   "source": [
    "Export to Python list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "series-to-list",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-to-list\n",
    "s.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acadd267",
   "metadata": {},
   "source": [
    "Export to Numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "series-to-numpy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-to-numpy\n",
    "s.to_numpy() # useful for preparing data for learning with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a595e",
   "metadata": {},
   "source": [
    "Export to Pandas Series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "series-to-Pandas-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-to-Pandas-series\n",
    "s.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35341d59",
   "metadata": {},
   "source": [
    "Export to Arrow Array.\n",
    "Useful for preparing data for learning with XGBoost which supports Arrow.\n",
    "Maybe Scikit-learn will also support Arrow in the future? Although Scikit-learn [may support Polars](https://github.com/scikit-learn/scikit-learn/issues/25896) before it supports Arrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "series-to-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-to-arrow\n",
    "s.to_arrow() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8aa66f",
   "metadata": {},
   "source": [
    "## Memory Representation of Series\n",
    "\n",
    "Object size in memory. \n",
    "Super useful for profiling.\n",
    "Will only be available for eager objects; by definitions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "series-memory-size",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-memory-size\n",
    "s.estimated_size(unit=\"b\") # 8(bytes) * 3(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c816d1ff",
   "metadata": {},
   "source": [
    "## Filtering and Subsetting {#sec-filtering-subsetting-series}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "17920860",
   "metadata": {},
   "outputs": [],
   "source": [
    "s[0] # same as s.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33542c49",
   "metadata": {},
   "source": [
    "To filter, you need to use the `.filter()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "series-filter-with-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-filter-with-series\n",
    "s.filter(pl.Series(\"a\", [True, False, True])) # works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c134c7bd",
   "metadata": {},
   "source": [
    "Filtering with the `[` operator will not work:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "series-subset-with-boolean",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-subset-with-boolean\n",
    "#| eval: false\n",
    "s[[True, False, True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "series-filter-with-list",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-filter-with-list\n",
    "s.filter([True, False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "series-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-limit\n",
    "s.limit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "series-head",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-head\n",
    "s.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "series-tail",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-tail\n",
    "s.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "series-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-sample\n",
    "s.sample(2, with_replacement=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "series-gather-aka-iloc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-gather-aka-iloc\n",
    "s.gather([0, 2]) # same as s[0,2] and Pandas .iloc[[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "series-slice",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-slice\n",
    "s.slice(1, 2) # same as Pandas .iloc[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "series-gather-every",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-gather-every\n",
    "s.gather_every(2) # same as Pandas .iloc[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875f90c8",
   "metadata": {},
   "source": [
    "## Aggregations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "series-sum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-sum\n",
    "s.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "series-min",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-min\n",
    "s.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "series-arg-min",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-arg-min\n",
    "s.arg_min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "series-max",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-max\n",
    "s.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "series-arg-max",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-arg-max\n",
    "s.arg_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "series-mean",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-mean\n",
    "s.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "series-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-median\n",
    "s.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "series-quantile",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-quantile\n",
    "s.quantile(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "series-entropy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-entropy\n",
    "s.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "Polars-series-describe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Polars-series-describe\n",
    "s.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8bb06e",
   "metadata": {},
   "source": [
    "Polars `pl.series.describe()` is almost the same as Pandas `pd.series.describe()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "Pandas-series-describe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Pandas-series-describe\n",
    "s_Pandas.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "series-value-counts",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-value-counts\n",
    "s.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3abb3b",
   "metadata": {},
   "source": [
    "## Missing\n",
    "\n",
    "Thanks to Arrow, Polars has built in missing value support for all(!) dtypes. \n",
    "This has been a long awaited feature in the Python data science ecosystem with implications on speed, memory, style and more. \n",
    "The [Polars User Guide](https://pola-rs.github.io/Polars-book/user-guide/howcani/missing_data.html) has a great overview of the topic from which we collect some take-homes:\n",
    "\n",
    "- `np.nan` is also supported along `pl.Null`, but is not considered as a missing value by Polars. This has implications on null counts, statistical aggregations, etc.\n",
    "- `pl.Null`, and `np.nan`s have their own separate functions for imputing, counting, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2a42a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pl.Series(\"a\", [1, 2, None, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "44440f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.is_null() # checking for None's. Like Pandas .isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9a7210c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.is_nan() # checking for np.nan's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a0a9a",
   "metadata": {},
   "source": [
    "For comparison with Pandas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "62d6d0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_Pandas = pd.Series([1, 2, None, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4746e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_Pandas.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cd7fef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_Pandas.isnull() # alias for pd.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62456c6e",
   "metadata": {},
   "source": [
    "### Operating on Missing\n",
    "\n",
    "We now compare the behavior of Polars to Pandas when operating on missing values.\n",
    "When interpreting the following remember:\n",
    "\n",
    "1. For Polars, nan is not missing. It is some unknown number. \n",
    "2. For Pandas, nan and Nulls are the same. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "344b107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polars\n",
    "m1 = pl.Series(\"a\", [1, None, 2, ]) # python native None\n",
    "m2 = pl.Series(\"a\", [1, np.nan, 2, ]) # numpy's nan\n",
    "m3 = pl.Series(\"a\", [1, float('nan'), 2, ]) # python's nan\n",
    "\n",
    "# Pandas\n",
    "m4 = pd.Series([1, None, 2 ])\n",
    "m5 = pd.Series([1, np.nan, 2, ])\n",
    "m6 = pd.Series([1, float('nan'), 2, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "25df275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "  m1.sum(), \n",
    "  m2.sum(), \n",
    "  m3.sum(), \n",
    "  m4.sum(), \n",
    "  m5.sum(), \n",
    "  m6.sum(),\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb527899",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    "-   `None` will be ignored by both, which is **unsafe**.\n",
    "-   `np.nan` will be ignored by Pandas (unsafe), but not by Polars (safe).\n",
    "\n",
    "Filling missing values; `None` and `np.nan` are treated differently:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "series-fill-null-for-null",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-fill-null-for-null\n",
    "m1.fill_null(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "series-fill-null-for-nan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-fill-null-for-nan\n",
    "m2.fill_null(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "series-fill-nan-for-nan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-fill-nan-for-nan\n",
    "m2.fill_nan(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "series-drop-null-for-null",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-drop-null-for-null\n",
    "m1.drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "series-drop-nan-for-null",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-drop-nan-for-null\n",
    "m1.drop_nans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "series-drop-null-for-nan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-drop-null-for-nan\n",
    "m2.drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "series-interpolate-null-for-null",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-interpolate-null-for-null\n",
    "m1.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "series-interpolate-null-for-nan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-interpolate-null-for-nan\n",
    "m2.interpolate() # np.nan is not considered missing, so why interpolate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2171a2c",
   "metadata": {},
   "source": [
    "## Shape Transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "series-to-dummies",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-to-dummies\n",
    "s.to_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "series-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-shift\n",
    "s.shift(1, fill_value=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "series-shift-back",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-shift-back\n",
    "s.shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "series-reshape",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-reshape\n",
    "pl.Series(\"a\",[1,2,3,4]).reshape((2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb9386",
   "metadata": {},
   "source": [
    "## Arithmetic Operations\n",
    "\n",
    "The following will fail for `pl.Series` for will work(!) for `pl.Expr`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "series-add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-add\n",
    "#| eval: false\n",
    "\n",
    "s.add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "series-sub",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-sub\n",
    "#| eval: false\n",
    "\n",
    "s.sub(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "series-mul",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-mul\n",
    "#| eval: false\n",
    "\n",
    "s.mul(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "series-truediv",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-truediv\n",
    "#| eval: false\n",
    "\n",
    "s.truediv(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "series-floordiv",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-floordiv\n",
    "#| eval: false\n",
    "\n",
    "s.floordiv(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123327ff",
   "metadata": {},
   "source": [
    "## Mathematical Transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "series-abs",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-abs\n",
    "s.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "series-sin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-sin\n",
    "s.sin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "series-exp",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-exp\n",
    "s.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "series-hash",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-hash\n",
    "s.hash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "series-log",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-log\n",
    "s.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "series-sqrt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-sqrt\n",
    "s.sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7616b461",
   "metadata": {},
   "source": [
    "## Comparisons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "217c4cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.equals(pl.Series(\"a\", [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "series-eq",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-eq\n",
    "s.eq(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "series-ge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-ge\n",
    "s.ge(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e22bc4b",
   "metadata": {},
   "source": [
    "Clip, aka Winsorize. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "series-clip",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-clip\n",
    "f.clip(lower_bound=1.5,upper_bound=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "series-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-round\n",
    "f.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "series-ceil",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-ceil\n",
    "f..add()ceil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "series-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-floor\n",
    "f.floor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "series-which-max",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-which-max\n",
    "s.peak_max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d7e870",
   "metadata": {},
   "source": [
    "## Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "series-search-in-list",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-search-in-list\n",
    "s.is_in([1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "series-search-in-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-search-in-range\n",
    "s.is_between(2, 3, closed='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c677e86",
   "metadata": {},
   "source": [
    "## Apply (map_elements)\n",
    "\n",
    "Applying your own function. \n",
    "Also note the informative error message (introduced in Polars Ver 0.18.0) that will try to recommend a more efficient way to do things.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2d1b15d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.map_elements(lambda x: x + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b97b73",
   "metadata": {},
   "source": [
    "Are lambda functions really so much slower?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d1c2db25",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pl.Series(np.random.randn(int(1e6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb67342",
   "metadata": {},
   "source": [
    "Adding 1 with apply:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2b34f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n2 -r2 s1.map_elements(lambda x: x + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76fe11f",
   "metadata": {},
   "source": [
    "Adding 1 without apply:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8f138c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n2 -r2 s1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60d76f0",
   "metadata": {},
   "source": [
    "## Cumulative Operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "series-cum-max",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-cum-max\n",
    "s.cum_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "series-cumsum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-cumsum\n",
    "s.cum_sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "series-cumprod",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-cumprod\n",
    "s.cum_prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "series-ewm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-ewm\n",
    "s.ewm_mean(com=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef4505",
   "metadata": {},
   "source": [
    "## Differentiation Operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "series-diff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-diff\n",
    "s.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "series-pct-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-pct-change\n",
    "s.pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6745149",
   "metadata": {},
   "source": [
    "## Windowed Operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "series-rolling-mean",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-rolling-mean\n",
    "\n",
    "s.rolling_mean(window_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "series-rolling-sum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-rolling-sum\n",
    "\n",
    "s.rolling_sum(window_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "series-rolling-map",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-rolling-map\n",
    "s.rolling_map(\n",
    "  sum, \n",
    "  window_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929c6ddb",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "- `sum` is the `pl.sum()` function. You cannot use arbitrary functions within a `rolling_map()` context. \n",
    "- Many rolling functions have been prepared. See the [computations section](https://docs.pola.rs/py-Polars/html/reference/series/computation.html) of the Series class in the official API.\n",
    "\n",
    "\n",
    "\n",
    "## Logical Aggregations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "make-boolean-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: make-boolean-series\n",
    "b = pl.Series(\"a\", [True, True, False])\n",
    "b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "series-all",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-all\n",
    "b.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "series-any",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-any\n",
    "b.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "series-not",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-not\n",
    "b.not_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae473a8",
   "metadata": {},
   "source": [
    "## Uniques and Duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "series-is-duplicated",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-is-duplicated\n",
    "s.is_duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "series-is-unique",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-is-unique\n",
    "s.is_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "series-n-unique",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-n-unique\n",
    "s.unique() # Same as Pandas drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "330402d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.n_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cae103ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Series([1,2,3,4,1]).unique_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "series-is-first-distinct",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-is-first-distinct\n",
    "s.is_first_distinct() # not sure there is a pl.Expr method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291465a2",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- `is_first_distinct()` has had many name changes in the past. It was `is_first()` in Polars 0.18.0, and `is_first_distinct()` in Polars 0.19.0.\n",
    "\n",
    "- Do not confuse `.is_first_distinct()` with `.first()`. The former is a logical aggregation, and the latter is a series method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "first-counter-examples",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: first-counter-examples\n",
    "(\n",
    "  pl.DataFrame(pl.Series(\"a\",[1,2,3,1]))\n",
    "  .select(\n",
    "    pl.col('a').first()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6275208",
   "metadata": {},
   "source": [
    "## Casting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c5b6c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.cast(pl.Int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776fc1a8",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    "-   `cast()` is Polars' equivalent of Pandas' `astype()`.\n",
    "-   The dtypes to cast to are **Polars** dtypes. Don't try `s.cast(\"int32\")`, `s.cast(np.int32)`, or `s.cast(pd.int)`\n",
    "-   For a list of dtypes see the official [documentation](see%20https://pola-rs.github.io/Polars/py-Polars/html/reference/datatypes.html).\n",
    "\n",
    "\n",
    "\n",
    "Find the most efficient dtype for a series; Like Pandas `pd.to_numeric(..., downcast=\"...\"`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f57f4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shrink_dtype().dtype # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d49ba",
   "metadata": {},
   "source": [
    "Also see [here](http://braaannigan.github.io/software/2022/10/31/Polars-dtype-diet.html).\n",
    "\n",
    "Shrink the memory allocation to the size of the actual data (in place).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c1e31827",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shrink_to_fit() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0aff19",
   "metadata": {},
   "source": [
    "## Ordering and Sorting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "series-sort",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-sort\n",
    "s.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "series-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-reverse\n",
    "s.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "series-rank",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-rank\n",
    "s.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "series-arg-sort",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-arg-sort\n",
    "s.arg_sort() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78039bd3",
   "metadata": {},
   "source": [
    "`arg_sort()` returns the indices that would sort the series. Same as R's `order()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "30d62cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_s = s[s.arg_sort()]\n",
    "(s.sort() == sorted_s).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "series-shuffle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: series-shuffle\n",
    "s.shuffle(seed=1) # random permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0819978e",
   "metadata": {},
   "source": [
    "## Date and Time\n",
    "\n",
    "There are 4 datetime dtypes in Polars:\n",
    "\n",
    "1.  **Date**: A date, without hours. Generated with `pl.Date()`.\n",
    "2.  **Datetime**: Date and hours. Generated with `pl.Datetime()`.\n",
    "3.  **Time**: Hour of day. Generated with `pl.Time()`.\n",
    "4.  **Duration**: As the name suggests. Similar to `timedelta` in Pandas. Generated with `pl.Duration()`.\n",
    "\n",
    "::: {.callout-warning}\n",
    "Python has a sea of modules that support datetimes. \n",
    "A partial list includes: [datetime module](https://docs.python.org/3/library/datetime.html), extensions in [dateutil](https://dateutil.readthedocs.io/en/stable/), [numpy](https://numpy.org/doc/stable/reference/arrays.datetime.html), [Pandas](https://Pandas.pydata.org/Pandas-docs/version/1.1/user_guide/timeseries.html), [arrow](https://arrow.readthedocs.io/en/latest/), the deprecated [scikits.timeseries](https://pytseries.sourceforge.net/) and certainly others. \n",
    "Be aware of the dtype you are using, and the accompanying methods.\n",
    ":::\n",
    "\n",
    "\n",
    "### Time Range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c7f9d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "date = (\n",
    "  pl.datetime_range(\n",
    "    start = datetime(\n",
    "      year= 2001, month=2, day=2, hour =2, minute=24, second=12), \n",
    "    end = datetime(\n",
    "      year=2002, month=2, day=5, hour =5, minute=34, second=45),\n",
    "    interval='1s', \n",
    "    eager= True, \n",
    "  )\n",
    "  .sample(10)\n",
    ")\n",
    "\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65679dc7",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    "-   How else could I have constructed this series? What other types are accepted as `start` and `end`?\n",
    "-   `pl.date_range` may return a series of dtype `Date` or `Datetime`. This depens of the granularity of the inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "bc0975dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cebb9b9",
   "metadata": {},
   "source": [
    "Cast to different time unit. \n",
    "May be useful when joining datasets, and the time unit is different.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b6aacd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.cast_time_unit(time_unit=\"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d2de30",
   "metadata": {},
   "source": [
    "Datetime methods are accessed with the `.dt` namespace.\n",
    "\n",
    "\n",
    "### Extract Time Sub-Units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "94d7da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.second()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f31dc509",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.minute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "dec49de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.hour()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d62537da",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "848577c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.week()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "30d29cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ab7e065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.month()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e0242a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.year()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "76caccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.ordinal_day() # day in year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ddc57981",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.quarter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0522452b",
   "metadata": {},
   "source": [
    "### Durations\n",
    "\n",
    "Equivalent to Pandas `period` dtype.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "29656cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = date.diff()\n",
    "diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "17d14392",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caf5022",
   "metadata": {},
   "source": [
    "::: {.callout-important}\n",
    "The extrator of sub-units from a `pl.Duration` has recently changed from `.dt.X()` to `.dt.total_X()`.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "102c0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs.dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7efd22ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs.dt.total_minutes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5f705302",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs.dt.days()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "32b16035",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs.dt.total_hours()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0956c502",
   "metadata": {},
   "source": [
    "### Date Aggregations\n",
    "\n",
    "Note that aggregating dates, returns a `datetime` type object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d28af8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e780afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0693d78f",
   "metadata": {},
   "source": [
    "I never quite undersootd that is the \"average day.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "07112862",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b0fc2ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f96ab23",
   "metadata": {},
   "source": [
    "### Date Transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2aa15377",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.offset_by(by=\"-100y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f63f55",
   "metadata": {},
   "source": [
    "Notice the syntax of `offset_by`. It is similar to R's `lubridate` package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9c89a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.offset_by(by=\"1y2m20d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d9d20485",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.truncate(\"1m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "28c75c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.round(every=\"1m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deec64ad",
   "metadata": {},
   "source": [
    "### From Date to String\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "58378bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.to_string(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1241ad29",
   "metadata": {},
   "source": [
    "Or equivalently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "97bf166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b7b333",
   "metadata": {},
   "source": [
    "### From String to Datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2a30c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = pl.Series(\n",
    "    \"date\",\n",
    "    [\n",
    "        \"2021-04-22\",\n",
    "        \"2022-01-04 00:00:00\",\n",
    "        \"01/31/22\",\n",
    "        \"Sun Jul  8 00:34:60 2001\",\n",
    "    ],\n",
    ")\n",
    "sd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3702f881",
   "metadata": {},
   "source": [
    "Parse into `Date` type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "9e442e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.str.to_date(format=\"%F\", strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f4e052",
   "metadata": {},
   "source": [
    "Or equivalently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "67bbfda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.str.strptime(dtype= pl.Date, format=\"%F\", strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "136c49fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.str.strptime(pl.Date, \"%D\", strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48475526",
   "metadata": {},
   "source": [
    "Parse into `Datetime` type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "aa940e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.str.to_datetime(format=\"%F %T\", strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb0e9f6",
   "metadata": {},
   "source": [
    "Or equivalently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "64a98e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.str.strptime(pl.Datetime, \"%F %T\", strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9dc942d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.str.strptime(pl.Datetime, \"%a %h %d %T %Y\",strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8d935c",
   "metadata": {},
   "source": [
    "Parse into `Time` dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "bb2617ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.str.to_time(\"%a %h %d %T %Y\",strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "76d14369",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.str.strptime(pl.Time, \"%a %h %d %T %Y\", strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd3d05",
   "metadata": {},
   "source": [
    "## Strings\n",
    "\n",
    "String methods are accessed with the `.str` namespace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "make-string-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: make-string-series\n",
    "st = pl.Series(\"a\", [\"foo\", \"bar\", \"baz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "string-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-length\n",
    "st.str.len_chars() # gets number of chars. In ASCII this is the same as lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "string-concat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-concat\n",
    "st.str.concat(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "string-count-matches",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-count-matches\n",
    "st.str.count_matches(pattern= 'o') # count literal matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "string-contains",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-contains\n",
    "st.str.contains(\"foo|tra|bar\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "string-contains-regrex",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-contains-regrex\n",
    "st.str.contains(\"ba[a-zA-Z]\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "string-contains-regex-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-contains-regex-2\n",
    "st.str.contains(\"[a-zA-Z]{4,5}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "string-count-matches-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-count-matches-2\n",
    "st.str.count_matches(pattern='[a-zA-Z]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "string-ends-with",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-ends-with\n",
    "st.str.ends_with(\"oo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "string-starts-with",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-starts-with\n",
    "st.str.starts_with(\"fo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c59bb4",
   "metadata": {},
   "source": [
    "To extract the **first** appearance of a pattern, use `extract`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "sample-strings",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: sample-strings\n",
    "url = pl.Series(\"a\", [\n",
    "            \"http://vote.com/ballon_dor?candidate=messi&ref=Polars\",\n",
    "\n",
    "            \"http://vote.com/ballon_dor?candidate=jorginho&ref=Polars\",\n",
    "\n",
    "            \"http://vote.com/ballon_dor?candidate=ronaldo&ref=Polars\"\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "string-extract",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-extract\n",
    "url.str.extract(\"=([a-zA-Z]+)\", 1) \n",
    "# \"=([a-zA-Z]+)\" is read: \"match an equality, followed by any number of alphanumerics\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02569b31",
   "metadata": {},
   "source": [
    "To extract **all** appearances of a pattern, use `extract_all`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "string-extract-all",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-extract-all\n",
    "url.str.extract_all(\"=(\\w+)\") # \\w is a shorthand for [a-zA-Z0-9_], i.e., alphanumerics and underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "string-pad-end",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-pad-end\n",
    "st.str.pad_end(8, \"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "string-pad-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-pad-start\n",
    "st.str.pad_start(8, \"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "string-strip-char-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-strip-char-start\n",
    "st.str.strip_chars_start('f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "string-strip-char-end",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-strip-char-end\n",
    "st.str.strip_chars_end('r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2587d7",
   "metadata": {},
   "source": [
    "Replacing first appearance of a pattern:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "string-replace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-replace\n",
    "st.str.replace(\"o+\", \"ZZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f900d",
   "metadata": {},
   "source": [
    "Replace all appearances of a pattern:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "string-replace-all",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-replace-all\n",
    "st.str.replace_all(\"o\", \"ZZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6778fa6",
   "metadata": {},
   "source": [
    "String to list of strings. Number of splits inferred.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "string-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-split\n",
    "st.str.split(by=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "string-split-inclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-split-inclusive\n",
    "st.str.split(by=\"a\", inclusive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a50542c",
   "metadata": {},
   "source": [
    "String to dict of strings. \n",
    "Number of **splits** fixed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "string-split-exact",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-split-exact\n",
    "st.str.split_exact(\"a\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1312e7b6",
   "metadata": {},
   "source": [
    "String to dict of strings. \n",
    "Length of **output** fixed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "string-split-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-split-length\n",
    "st.str.splitn(\"a\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a215bb6",
   "metadata": {},
   "source": [
    "Strip white spaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f3e2fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Series(['   ohh   ','   yeah   ']).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "string-to-uppercase",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-to-uppercase\n",
    "st.str.to_uppercase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "string-to-lowercase",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-to-lowercase\n",
    "st.str.to_lowercase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "string-to-titlecase",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-to-titlecase\n",
    "st.str.to_titlecase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "string-zfill",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-zfill\n",
    "st.str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "string-slice",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: string-slice\n",
    "st.str.slice(offset=1, length=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd4fee8",
   "metadata": {},
   "source": [
    "# Polars (Eager) DataFrames {#sec-dataframes}\n",
    "\n",
    "Recall :\n",
    "\n",
    "1.  There is no row index (like R's `data.frame`, `data.table`, and `tibble`; unlike Python's `Pandas`).\n",
    "2.  Will not accept duplicate column names (unlike Pandas).\n",
    "\n",
    "## Create\n",
    "\n",
    "A frame can be created as you would expect. From a dictionary of series, a numpy array, a Pandas sdataframe, or a list of Polars (or Pandas) series, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "make-dataframe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: make-dataframe\n",
    "\n",
    "df = pl.DataFrame({\n",
    "  \"integer\": [1, 2, 3], \n",
    "  \"date\": [\n",
    "    (datetime(2022, 1, 1)), \n",
    "    (datetime(2022, 1, 2)), \n",
    "    (datetime(2022, 1, 3))], \n",
    "    \"float\": [4.0, 5.0, 6.0],\n",
    "    \"string\": [\"a\", \"b\", \"c\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9447487",
   "metadata": {},
   "source": [
    "## Inspect\n",
    "\n",
    "Nice HTML printing to iPython. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c787a25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "45fae954",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "500d630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.glimpse() # useful for wide frames. Similar to R's str() of Pandas's .info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "f1fc3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c5d2fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "37f5f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.height # probably more useful than df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "50962091",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "559de96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.schema # similar to Pandas info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b8de8439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_row_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aa77bc",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    "1. `df.schema` and `df.columns` will be available for lazy objects, even before materializing them.\n",
    "2. `df.height` and `df.shape` will not be available for lazy objects, until they are materialized.\n",
    "\n",
    "## Intro to Column Operations\n",
    "\n",
    "::: {.callout-important}\n",
    "This is probably the most important section of the document.\n",
    ":::\n",
    "\n",
    "### Contexts {#sec-contexts}\n",
    "\n",
    "As discussed in @sec-api-principles, operations on columns will always be done within a **context**.\n",
    "Pandas fans may think of Polars Context as `.eval()` or `.assign()` Pandas methods.\n",
    "\n",
    "- `df.with_columns()` to add columns.\n",
    "- `df.select()` to select columns.\n",
    "- `df.group_by().agg()` is acutually `.select()` within a `group_by()` context.\n",
    "- `df.filter()` is a context for filtering rows. \n",
    "- `pl.when()` is a context for conditional operations.\n",
    "\n",
    "\n",
    "Select Context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "select-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: select-context\n",
    "df.select(pl.col(\"integer\").add(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "with-colummns-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: with-colummns-context\n",
    "df.with_columns(pl.col(\"integer\").add(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9e3dfe",
   "metadata": {},
   "source": [
    "Group-by context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "group-by-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: group-by-context\n",
    "df.group_by(\"string\").agg(pl.col(\"integer\").add(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83faf44",
   "metadata": {},
   "source": [
    "### Column Access\n",
    "\n",
    "Within a context there are many ways to access a column.\n",
    "Here are some examples of various ways of adding 1 to the integer column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "add-1-to-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: add-1-to-column\n",
    "#| lst-label: col-ref\n",
    "#| lst-cap: Referencing a Column in a Select Context\n",
    "df.select(pl.col(\"integer\").add(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b19d7690",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.col([\"integer\"]).add(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "60dd8b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.col(r\"^integer$\").add(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "91765dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.col(pl.Int64).add(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1adcb989",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.first().add(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7c036f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars.selectors as cs\n",
    "\n",
    "df.select(cs.by_name(\"integer\").add(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "b1283413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(cs.ends_with(\"ger\").add(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "2bff4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(cs.starts_with('int').add(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c66568b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(cs.integer().add(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "680ab507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(cs.first().add(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "00b5440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(cs.matches(r\"^integer$\").add(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9ee6d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(cs.contains(\"int\").add(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8501da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.col(\"integer\")+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "586ed575",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['integer']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "bd119864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.get_column('integer')+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0898c4",
   "metadata": {},
   "source": [
    "The following will not work because a series does not have a `.add(1)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "8ba0f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "df['integer'].add(1)\n",
    "df.get_column('integer').add(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e53e017",
   "metadata": {},
   "source": [
    "::: {.callout-important}\n",
    "Think: What are the differences between these methods?\n",
    ":::\n",
    "\n",
    "My preferred syntax is @col-ref, which is the one I will use in the rest of the document.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Convert to Other Python Objects\n",
    "\n",
    "You can always convert your `pl.Series` or `pl.DataFrame` to other Python objects.\n",
    "\n",
    "To Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "dataframe-to-Pandas",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-to-Pandas\n",
    "df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512a9ec5",
   "metadata": {},
   "source": [
    "To Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "dataframe-to-numpy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-to-numpy\n",
    "df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2651d8",
   "metadata": {},
   "source": [
    "To List of Polars Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "dataframe-to-list",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-to-list\n",
    "df.get_columns() # columns as list of Polars series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecafcd3",
   "metadata": {},
   "source": [
    "To list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "dataframe-to-list-of-tuples",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-to-list-of-tuples\n",
    "df.rows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d615c21b",
   "metadata": {},
   "source": [
    "To Dict of Polars Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "dataframe-to-dict-of-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-to-dict-of-series\n",
    "df.to_dict() # columns as dict of Polars series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c8bc1",
   "metadata": {},
   "source": [
    "To Dict of Python Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "dataframe-to-dict-of-lists",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-to-dict-of-lists\n",
    "df.to_dict(as_series=False) # columns as dict of Polars series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4331b059",
   "metadata": {},
   "source": [
    "To String Representation (`repr`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "dataframe-to-repr",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-to-repr\n",
    "df.to_init_repr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541e8566",
   "metadata": {},
   "source": [
    "To a Polars Series of Polars Struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "dataframe-to-struct",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-to-struct\n",
    "df.to_struct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be42350",
   "metadata": {},
   "source": [
    "To PyArrow Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "dataframe-to-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-to-arrow\n",
    "df.to_arrow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc12d144",
   "metadata": {},
   "source": [
    "## Statistical Aggregations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "dataframe-describe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-describe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeac020a",
   "metadata": {},
   "source": [
    "Compare to Pandas: Polars will summarize all columns even if they are not numeric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "dataframe-describe-pandas",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-describe-pandas\n",
    "df.to_pandas().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9137897b",
   "metadata": {},
   "source": [
    "Statistical aggregations operate column-wise (and in parallel!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "dataframe-max",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-max\n",
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "dataframe-min",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-min\n",
    "df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "dataframe-mean",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-mean\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "dataframe-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-median\n",
    "df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "dataframe-quantile",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-quantile\n",
    "df.quantile(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "dataframe-sum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-sum\n",
    "df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8215ca",
   "metadata": {},
   "source": [
    "Constrast with summation in row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "dataframe-sum-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-sum-horizontal\n",
    "df.with_columns(pl.sum_horizontal('*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65db6f",
   "metadata": {},
   "source": [
    "## Selections {#sec-filtering-subsetting-frames}\n",
    "\n",
    "1.  If you are used to Pandas, recall there is no index. There is thus no need for `loc` vs. `iloc`, `reset_index()`, etc. See [here](https://pola-rs.github.io/Polars-book/user-guide/howcani/selecting_data/selecting_data_indexing.html) for a comparison of extractors between Polars and Pandas.\n",
    "2.  Filtering and selection is possible with the `[` operator, or the `filter()` and `select()` methods. The latter is recommended to facilitate query planning (discussed in @sec-query-planning).\n",
    "\n",
    "### Selecting With Indices\n",
    "\n",
    "The following are presented for completeness. \n",
    "Gnerally, you can, and should, avoid selecting with indices. \n",
    "See @sec-selecting-columns for selecting columns, and @sec-filtering-rows for selecting rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "single-cell-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: single-cell-extraction\n",
    "df[0,0] # like Pandas .iloc[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d20df46",
   "metadata": {},
   "source": [
    "Slicing along rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "slice-rows",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: slice-rows\n",
    "df[0:1] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf65c05",
   "metadata": {},
   "source": [
    "Slicing along columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "slice-columns",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: slice-columns\n",
    "df[:,0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f7c3f",
   "metadata": {},
   "source": [
    "### Selecting Columns {#sec-selecting-columns}\n",
    "\n",
    "First- do you want to return a Polars frame or a Polars series?\n",
    "\n",
    "For a frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "706bc33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"integer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af97e538",
   "metadata": {},
   "source": [
    "For a series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "6195099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['integer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae33ed3",
   "metadata": {},
   "source": [
    "How do I know which is which? \n",
    "\n",
    "1. You can use `type()`.\n",
    "2. Notice the dimension of the index in the output. \n",
    "\n",
    "\n",
    "Select columns with list of labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "92c48f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select([\"integer\", \"float\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a4d88c",
   "metadata": {},
   "source": [
    "As of Polars\\>=15.0.0, you don't have to pass a list:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "bfeca33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"integer\", \"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0322d0aa",
   "metadata": {},
   "source": [
    "Column slicing by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "00ed39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:,\"integer\":\"float\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2320bcc",
   "metadata": {},
   "source": [
    "Note: `df.select()` does not support slicing ranges such as `df.select(\"integer\":\"float\")`. \n",
    "\n",
    "Get a column as a Polars Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "c8cfd4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.get_column('integer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe6458a",
   "metadata": {},
   "source": [
    "Get a column as a Polars series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "d508afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_series(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "547e7470",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.get_column_index('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "60119142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"integer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e8c0e",
   "metadata": {},
   "source": [
    "`df.drop()` not have an `inplace` argument. Use `df.drop_in_place()` instead.\n",
    "\n",
    "\n",
    "\n",
    "### pl.col()\n",
    "\n",
    "The `pl.col()` is **super important**. It allows you to select columns in many ways, and provides almost all the methods (i.e. Polars Expressions) you will need to operate on them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "1cfb5ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.col(pl.Int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "3efe2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.col(pl.Float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "6266d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.col(pl.Utf8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08365ac0",
   "metadata": {},
   "source": [
    "Python List of Polars dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "5d1022b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.col([pl.Int64, pl.Float64]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ff34a",
   "metadata": {},
   "source": [
    "Patterns (\"glob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "47407816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.col(\"*\")) # same as df.select(pl.all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c6ec0d",
   "metadata": {},
   "source": [
    "Regular Expression. Important! Use `pl.col('^<patterh>$')` to match regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "d643fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.col(\"^\\w{4}$\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "7bdc8ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.col('^.*g$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "pl-col-with-regex",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: pl-col-with-regex\n",
    "df.select(pl.col(\"^.*te.*$\")) # regex matching anything with a \"te\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d799909",
   "metadata": {},
   "source": [
    "You can use `pl.col()` to exclude columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "4116e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.col(\"*\").exclude(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "356bcc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.col(\"*\").exclude(pl.Float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7f04cb",
   "metadata": {},
   "source": [
    "Exciting! [New API](https://pola-rs.github.io/Polars/py-Polars/html/reference/selectors.html) for column selection. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "pl-column-selector",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: pl-column-selector\n",
    "import polars.selectors as cs\n",
    "\n",
    "df.select(cs.starts_with('i'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "pl-column-selector-set-opeartions",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: pl-column-selector-set-opeartions\n",
    "\n",
    "df.select(cs.starts_with('i') | cs.starts_with('d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "5545c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(cs.starts_with('i') | cs.starts_with('d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0488fe",
   "metadata": {},
   "source": [
    "### Selecting Rows By Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "025f5668",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.limit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "fb75360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "ecad8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "ed599cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.take_every(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "b0042318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.slice(offset=1, length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "5ddca09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a5da8c",
   "metadata": {},
   "source": [
    "Because `.sample()` requires row counts, it will not work for lazy objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "9cf0b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.row(1) # get row as tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4106964",
   "metadata": {},
   "source": [
    "### Selecting Rows By Condition {#sec-filtering-rows}\n",
    "\n",
    "Aka [Projection](https://en.wikipedia.org/wiki/Projection_(relational_algebra)). \n",
    "\n",
    "Enter the `df.filter()` context. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "filter-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: filter-context\n",
    "#| lst-label: filter-context\n",
    "#| lst-cap: Filtering Rows in a DataFrame\n",
    "\n",
    "df.filter(pl.col(\"integer\").eq(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978416e4",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    "- `df.filter()` is a **Polars Context**. \n",
    "- It is a **keep** filter, not a **drop** filter: it will evaluate expressions, and return the rows where the expression does not evaluate to `False`. \n",
    "-   The `[` operator does not support indexing with boolean such as `df[df[\"integer\"] == 2]`.\n",
    "-   The `filter()` method is recommended over `[` by the authors of Polars, to facilitate lazy evaluation (discussed later).\n",
    "\n",
    "\n",
    "An alternative syntax for equality filtering, known as **constraint** in the Polars documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "e624a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(integer = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8a84f3",
   "metadata": {},
   "source": [
    "AND conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "filter-and",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: filter-and\n",
    "df.filter(\n",
    "  pl.col('integer').eq(2),\n",
    "  pl.col('float').gt(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "filter-and-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: filter-and-2\n",
    "df.filter(\n",
    "  pl.col('integer').eq(2) &\n",
    "  pl.col('float').gt(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aa9aea",
   "metadata": {},
   "source": [
    "OR conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "filter-or",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: filter-or\n",
    "df.filter(\n",
    "  pl.col('integer').eq(2) |\n",
    "  pl.col('float').gt(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca46d91e",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "How would you write an AND, or OR condition, without using the comparison methods `.eq()`, `.gt()`, etc.?\n",
    ":::\n",
    "\n",
    "\n",
    "### Selecting From Single Item Frame\n",
    "\n",
    "Say your operation returned a Polars frame with a single float, which you want to manipulate as a Python float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "single-item-to-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: single-item-to-python\n",
    "pl.DataFrame([1]).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c4e52",
   "metadata": {},
   "source": [
    "## Column Transformations \n",
    "\n",
    "1. Transformations are done with Polars Expressions (@sec-expressions) within a **context** (see @sec-contexts).\n",
    "-   The output column will have the same name as the input, unless you use the `alias()` method to rename it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "with-columns",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: with-columns\n",
    "df.with_columns(\n",
    "    pl.col(\"integer\").mul(2),\n",
    "    pl.col(\"integer\").alias(\"integer2\"),\n",
    "    integer3 = pl.col(\"integer\").truediv(3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a7f897",
   "metadata": {},
   "source": [
    "Warning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "308c697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "df.with_columns(\n",
    "    integer3 = pl.col(\"integer\").truediv(3),\n",
    "    pl.col(\"integer\").mul(2),\n",
    "    pl.col(\"integer\").alias(\"integer2\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8878ccc",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    "-   You cannot use `[` to assign! This would not have worked `df['integer3'] = df['integer'] * 2`\n",
    "-   The columns `integer` is multiplied by 2 **in place**, because no `alias` is used.\n",
    "-   As of Polars version \\>15.*.* (I think), you can use `=` to assign. That is how `integer3` is created.\n",
    "-   The column `integer` is copied, by renaming it to `integer2`.\n",
    "-   Why `.truediv()`? To distinguish from `.floordiv()` and `.mod()`.\n",
    "\n",
    "If a selection returns multiple columns, all will be transformed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "with-columns-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: with-columns-multiple\n",
    "df.with_columns(\n",
    "    pl.col([pl.Int64,pl.Float64]).mul(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "with-columns-all-cast",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: with-columns-all-cast\n",
    "df.with_columns(\n",
    "    pl.all().cast(pl.Utf8)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801afec",
   "metadata": {},
   "source": [
    "You cannot `.alias()` when operating on multiple columns. But you can use `.name.suffix()` or `.name.prefix()` from the `.name.` namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "with-columns-multiple-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: with-columns-multiple-2\n",
    "df.with_columns(\n",
    "    pl.col([pl.Int64,pl.Float64]).mul(2).name.suffix(\"_2X\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50313973",
   "metadata": {},
   "source": [
    "### Transform the Transformed Columns\n",
    "\n",
    "All the expressions within a context see the frame as it's initial state. \n",
    "Recall, odds are expressions will be evaluated in parallel, and not sequentially. \n",
    "So how can I operate on columns I have just transformed?\n",
    "By chaining contexts!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "chained-contexts",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: chained-contexts\n",
    "(\n",
    "  df\n",
    "  .with_columns(\n",
    "    pl.col(\"integer\").truediv(pl.col(\"float\")).alias(\"ratio\")\n",
    "  )\n",
    "  .with_columns(\n",
    "    pl.col(\"ratio\").mul(100)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdab09ff",
   "metadata": {},
   "source": [
    "### Conditional Transformation (if-else)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "conditional-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: conditional-transformation\n",
    "df.with_columns(\n",
    "    pl.when(\n",
    "      pl.col(\"integer\").gt(2)\n",
    "    )\n",
    "    .then(pl.lit(1))\n",
    "    .otherwise(pl.col(\"integer\"))\n",
    "    .alias(\"new_col\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae90bda8",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    "-  The `otherwise()` method is optional. If omitted, the original column will be returned (see next example).\n",
    "-  `pl.lit(1)` is a Polars expression that returns the literal 1. It may be ommited, but it is good practice to include it for clarity and safety.\n",
    "-  `pl.col(\"integer\").gt(2)` could have been replaced with `pl.col(\"integer\") > 2`. I like the former because it allows easier composition of conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "5dde75ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_columns(\n",
    "    pl.when(\n",
    "      pl.col(\"integer\") > 2\n",
    "    )\n",
    "    .then(1)\n",
    "    .otherwise(pl.col(\"integer\"))\n",
    "    .alias(\"new_col\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a326b7",
   "metadata": {},
   "source": [
    "### Python Lambda Functions\n",
    "\n",
    "Apply your own lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "0f2912c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select([pl.col(\"integer\"), pl.col(\"float\")]).map_rows(lambda x: x[0] + x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4679e68",
   "metadata": {},
   "source": [
    "As usual, using your own functions may have a very serious toll on performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "ec4f5c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big = pl.DataFrame(np.random.randn(1000000, 2), schema=[\"a\", \"b\"]) # previous versions used columns= instead of schema="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "70363c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n2 -r2 df_big.sum_horizontal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "5420455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n2 -r2 df_big.map_rows(lambda x: x[0] + x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b4b57c",
   "metadata": {},
   "source": [
    "### Numpy Ufuncs\n",
    "\n",
    "You can use Numpy's universal functions (ufuncs) on Polars frames. \n",
    "There is little overhead in using Numpy ufuncs.\n",
    "\n",
    "- See [here](https://docs.pola.rs/user-guide/expressions/numpy/) to use Numpy   ufuncs in Polars.\n",
    "- See [here](https://www.w3schools.com/python/numpy/numpy_ufunc_create_function.asp) to create your own Numpy ufunc's.\n",
    "\n",
    "Applying off-the-shelf Numpy ufuncs is as simple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "numpy-ufunc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: numpy-ufunc\n",
    "\n",
    "df.select(pl.col('integer').pipe(np.sin))\n",
    "# the same as \n",
    "# df.select(np.sin(pl.col('integer')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1d0dc2",
   "metadata": {},
   "source": [
    "Writing your own Numpy ufunc is easy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "numpy-ufunc-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: numpy-ufunc-2\n",
    "\n",
    "def myfunc(x):\n",
    "  return x**2 + 2*x + 1\n",
    "\n",
    "# make myfunc a ufunc\n",
    "myfunc_ufunc = np.frompyfunc(myfunc, 1, 1)\n",
    "\n",
    "df.select(\n",
    "  pl.col('float').pipe(myfunc_ufunc, casting='unsafe')\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885938c6",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    "- My Ufunc is created with `np.frompyfunc()`. It could have also been created with `np.vectorize()`.\n",
    "- The `casting='unsafe'` argument is required, to deal with dtype mismatch. There could be a more elegant way, but I did not find it. \n",
    "- Calling a **Ufunc with multiple arguments** is slightly more involved, and I currently did not find a \"clean\" solution. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Uniques and Duplicates\n",
    "\n",
    "Keep uniques; same as `pd.drop_duplicates()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "dataframe-unique",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-unique\n",
    "df.unique() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb5e716",
   "metadata": {},
   "source": [
    "Can be used with column subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "dataframe-unique-subset",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-unique-subset\n",
    "df.unique([\"integer\", \"float\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "223ccca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "7f44d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "2a735292",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.n_unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452b3dda",
   "metadata": {},
   "source": [
    "## Missing\n",
    "\n",
    "Make some data with missing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "make-dataframe-with-nulls",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: make-dataframe-with-nulls\n",
    "df_with_nulls = df.with_columns(\n",
    "    null_1 = pl.Series(\"missing\", [3, None, np.nan]),\n",
    "    null_2 = pl.Series(\"missing\", [None, 5, 6]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "dataframe-with-nulls",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: dataframe-with-nulls\n",
    "df_with_nulls.null_count() # same as pd.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "df-drop-nulls",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: df-drop-nulls\n",
    "df_with_nulls.drop_nulls() # same as pd.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d513d494",
   "metadata": {},
   "source": [
    "Can I also drop `np.nan`'s? \n",
    "There is no `drop_nan()` method. \n",
    "See [StackOverflow](https://stackoverflow.com/questions/75548444/Polars-dataframe-drop-nans) for workarounds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "df-fill-nulls",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: df-fill-nulls\n",
    "df_with_nulls.fill_null(0) # same as pd.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e75f52",
   "metadata": {},
   "source": [
    "But recall that `None` and `np.nan` are not the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "df-fill-nans",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: df-fill-nans\n",
    "df_with_nulls.fill_nan(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "df-null-interpolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: df-null-interpolate\n",
    "df_with_nulls.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411405c6",
   "metadata": {},
   "source": [
    "## Sorting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "82795985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort(by=[\"integer\",\"float\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "9a3e0523",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reverse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1458124a",
   "metadata": {},
   "source": [
    "## Groupby\n",
    "\n",
    "High level:\n",
    "\n",
    "-   `df.group_by()` is a **context**, for grouping. Just like Pandas, only parallelized, etc. The output will have as many rows as the number of groups.\n",
    "-   `df.partion_by()` will return a **list** of frames.\n",
    "-   `pl.col().expression().over()` is like Pandas `df.groupby.transform()`: will will not collapse rows in the original frame. Rather, it will assign each row in the original frame with the aggregate in the group. The output will have the same number of rows as the input. \n",
    "\n",
    "Grouping over time:\n",
    "\n",
    "-   `df.grouby_rolling()` for rolling window grouping, a.k.a. a sliding window. Each row will be assigned the aggregate in the window.\n",
    "-   `df.group_by_dynamic()` for dynamic grouping. Each period will be assigned the agregate in the period. The output may have more rows than the input.\n",
    "\n",
    "\n",
    "\n",
    "The `group_by()` context will be followed by an aggregation:\n",
    "\n",
    "1.   `df.group_by().agg()`: an aggregating context. \n",
    "2.   `df.group_by().apply()`: deprecated and replaced by `df.group_by().map_groups()`.\n",
    "3.   `df.group_by().map_groups()`: to apply your own function to each group.\n",
    "\n",
    "See the [API reference](https://docs.pola.rs/py-polars/html/reference/dataframe/api/polars.DataFrame.group_by.html) for the various options. \n",
    "Also see the [user guide](https://docs.pola.rs/user-guide/transformations/time-series/rolling/) for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "ff89737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pl.DataFrame({\n",
    "    \"integer\": [1, 1, 2, 2, 3, 3],\n",
    "    \"float\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0],\n",
    "    \"string\": [\"a\", \"b\", \"c\", \"c\", \"d\", \"d\"],\n",
    "    \"datetime\": [\n",
    "        (datetime(2022, 1, 4)), \n",
    "        (datetime(2022, 1, 4)), \n",
    "        (datetime(2022, 1, 4)), \n",
    "        (datetime(2022, 1, 9)), \n",
    "        (datetime(2022, 1, 9)), \n",
    "        (datetime(2022, 1, 9))],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e902e889",
   "metadata": {},
   "source": [
    "### partition_by()\n",
    "\n",
    "Make the list of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "partition-by",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: partition-by\n",
    "partitioner = df2.partition_by(\"integer\")\n",
    "partitioner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317b05f8",
   "metadata": {},
   "source": [
    "The iterate like any Python list, with a function that operates on Polars frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "47c01f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(\n",
    "  df: pl.DataFrame\n",
    "  ) -> pl.DataFrame:\n",
    "  return df.select(pl.col(\"float\").sum())\n",
    "\n",
    "for df in partitioner: \n",
    "  print(myfunc(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5a92c9",
   "metadata": {},
   "source": [
    "### group_by()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "group-by",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: group-by\n",
    "groupper = df2.group_by(\"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "1ad99005",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupper.agg(\n",
    "  cs.numeric().sum().name.suffix(\"_sum\"),\n",
    "  pl.col('string').n_unique().name.suffix(\"_n_unique\"),\n",
    "  pl.col('string'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367b6fb5",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    "- Don't expect an index. This is Polars, not Pandas.\n",
    "- The grouping may be saved as an object, and used later.\n",
    "- The `group_by()` and `.agg()` contexts offer the usual functonality of `.select()` and `.with_columns()`. In particular, you can use `pl.col()` to access columns, or the `pl.selector` module (`cs`).\n",
    "- In the selector is not followed by an expression, it will collapse the Series to a Polars List (see @sec-nested-dtypes). \n",
    "\n",
    "Some random/useful examples now follow.\n",
    "\n",
    "#### Examples\n",
    "\n",
    "The count (length) of each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "b00dd2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupper.agg(pl.len())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ba453",
   "metadata": {},
   "source": [
    "When operating on all columns,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "29e8cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupper.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "9809c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupper.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ff549c",
   "metadata": {},
   "source": [
    "### over()\n",
    "\n",
    "You may be familar with Pandas `group_by().transform()`, which will return a frame with the same row-count as its input. \n",
    "You may be familiar with Postgres SQL [window function](https://www.postgresql.org/docs/current/tutorial-window.html). \n",
    "You may not be familiar with neither, and still want to aggregate within group, but propagate the result to all group members. \n",
    "Polars' `.over()` is the answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "over",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: over\n",
    "df2.with_columns(\n",
    "  pl.col(\"float\").sum().over(\"string\").alias(\"sum\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33baafe4",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    "- The output will have the same number of rows as the input.\n",
    "- `.over()` is a **context**. As such, you can evaluate column selectors and expressions within it.\n",
    "- **Careful**: `over()` should be the last operation in a chain. @over-wrong will sadly **not fail**, while it should have.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "over-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: over-wrong\n",
    "#| lst-label: over-wrong\n",
    "#| lst-cap: A wrong use of over()\n",
    "\n",
    "df2.with_columns(\n",
    "  pl.col(\"float\").over(\"string\").sum().alias(\"sum\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f046ff5e",
   "metadata": {},
   "source": [
    "### Grouping on time\n",
    "\n",
    "High level:\n",
    "\n",
    "1. Grouping on time is special, because a temporal variable implies multiple resolutions which may be used for grouping. E.g. a date may be grouped by year, month, day, etc.\n",
    "2. For a temporal version of `group_by()`, use `df.group_by_dynamic()`.\n",
    "3. For a temporal version of `over()`, use `df.rolling()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "group-by-dynamic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: group-by-dynamic\n",
    "(\n",
    "  df2\n",
    "  .sort(\"datetime\")\n",
    "  .group_by_dynamic(\n",
    "    index_column=\"datetime\", \n",
    "    every=\"1d\",\n",
    "    )\n",
    "  .agg(pl.col(\"float\").sum())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: rolling\n",
    "(\n",
    "  df2\n",
    "  .sort(\"datetime\")\n",
    "  .rolling(\n",
    "    index_column=\"datetime\", \n",
    "    period='1d',\n",
    "    )\n",
    "  .agg(pl.col(\"float\").sum())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675f80d0",
   "metadata": {},
   "source": [
    "## Joins {#sec-joins}\n",
    "\n",
    "High level:\n",
    "\n",
    "-   `df.join()` for joins; like Pandas `pd.merge()` or `df.join()`.\n",
    "-  `df.join_asof()` for asof joins; like Pandas `pd.merge_asof()`.\n",
    "-   `df.hstack()` for horizontal concatenation; like Pandas `pd.concat([],axis=1)` or R's `cbind`.\n",
    "-   `df.vstack()` for vertical concatenation; like Pandas `pd.concat([],axis=0)` or R's `rbind`.\n",
    "-   `df.merge_sorted()` for vertical stacking, with sorting.\n",
    "-   `pl.concat()`, which is similar to the previous two, but with memory re-chunking. `pl.concat()` also allows diagonal concatenation, if columns are not shared.\n",
    "-   `df.extend()` for vertical concatenation, but with memory re-chunking. Similar to `df.vstack().rechunk()`.\n",
    "\n",
    "For more on the differences between these methods, see [here](https://www.rhosignal.com/posts/Polars-extend-vstack/).\n",
    "\n",
    "### join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "join",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: join\n",
    "\n",
    "df2 = pl.DataFrame({\n",
    "  \"integer\": [1, 2, 3], \n",
    "  \"date\": [\n",
    "    (datetime(2022, 1, 4)), \n",
    "    (datetime(2022, 1, 5)), \n",
    "    (datetime(2022, 1, 6))], \n",
    "    \"float\":[7.0, 8.0, 9.0],\n",
    "    \"string\": [\"d\", \"d\", \"d\"]})\n",
    "\n",
    "\n",
    "df.join(\n",
    "  df2, \n",
    "  on=\"integer\", \n",
    "  how=\"left\",\n",
    "  validate='m:1'\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56323ec",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    "-   Repeating column names have been suffixed with \"\\_right\".\n",
    "-   Recall, there are **no indices**. The `on`/`left_on`/`right_on` argument is always required.\n",
    "- `how=` may take the following values: 'inner', 'left', 'outer', 'semi', 'anti', 'cross'. 'inner' is the default. \n",
    "- I like to add the `validate=` argument, for safety. \n",
    "- The join is super fast, as demonstrated in @sec-motivation above.\n",
    "\n",
    "\n",
    "### join_asof()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "983c91f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.join_asof(\n",
    "    df2, \n",
    "    left_on=\"date\", \n",
    "    right_on='date', \n",
    "    by=\"integer\", \n",
    "    strategy=\"backward\", \n",
    "    tolerance='1w',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0c7655",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    "-   Yes! `join_asof()` is available. In streaming engine as well!\n",
    "-   The `strategy=` argument may take the following values: 'backward', 'forward'.\n",
    "-   The `tolerance=` argument may take the following values: '1w', '1d', '1h', '1m', '1s', '1ms', '1us', '1ns'.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "hstack",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: hstack\n",
    "new_column = pl.Series(\"c\", np.repeat(1, df.height))\n",
    "\n",
    "df.hstack([new_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99772fe",
   "metadata": {},
   "source": [
    "### vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "vstack",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: vstack\n",
    "\n",
    "df.vstack(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3d832a",
   "metadata": {},
   "source": [
    "Caution: Joining along rows is possible only if matched columns have the same dtype. Timestamps may be tricky because they may have different time units. Recall that timeunits may be cast before joining using `series.dt.cast_time_unit()`. \n",
    "Here is a demonstration of the problem:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "vstack-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: vstack-caution\n",
    "#| eval: false\n",
    "(\n",
    "  df\n",
    "  .vstack(\n",
    "    df2\n",
    "    .with_columns(\n",
    "      pl.col('date').dt.cast_time_unit(time_unit=\"ms\")\n",
    "      )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b6a528",
   "metadata": {},
   "source": [
    "### merge_sorted\n",
    "\n",
    "This is a **vertical** stacking, when expecting a sorted result, and assuming inputs are sorted. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "7e4db560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge_sorted(df2, key=\"integer\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23431f79",
   "metadata": {},
   "source": [
    "### concat()\n",
    "\n",
    "Vertical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "cb1b871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.concat([df, df2]) \n",
    "# equivalent to:\n",
    "# pl.concat([df, df2], how='vertical', rechunk=True, parallel=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7084bbc",
   "metadata": {},
   "source": [
    "Horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "e9f002b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.concat(\n",
    "  [df,new_column.to_frame()], \n",
    "  how='horizontal',\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6563c4",
   "metadata": {},
   "source": [
    "Diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "0aa17b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.concat(\n",
    "  [df,new_column.to_frame()], \n",
    "  how='diagonal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbf7e25",
   "metadata": {},
   "source": [
    "What is the difference between `pl.concat()` and `df.vstack()` and `hstack()`?\n",
    "`pl.concat()` is more general with more functionality.\n",
    "\n",
    "- concat includes re-chunking, which is useful for memory management.\n",
    "- concat includes diagonal concatenation, which is useful when columns are not shared.\n",
    "- concat includes parallel execution, which is useful for performance.\n",
    "- concat has recenetly been equipped with `how=vertial_relaxed` and `how=horizontal_relaxed`, which finds a common dtype if schemas are mismatched.\n",
    "\n",
    "\n",
    "\n",
    "### extend()\n",
    "\n",
    "Like `vstack()`, but with memory re-chunking. Similar to `df.vstack().rechunk()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "06252cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.extend(df2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51c4806",
   "metadata": {},
   "source": [
    "Why should I care about re-chunking?\n",
    "Since Polar is a columnar store, it is important to have contiguous memory layout. Otherwise, you may not enjoy the benefits of vectorized operations. \n",
    "\n",
    "Is there a method for `df.hstack().rechunk()`?\n",
    "No. \n",
    "A columnar storage is not sensitive to emory framgmentation along columns.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Reshaping\n",
    "\n",
    "High level:\n",
    "\n",
    "-   `df.transpose()` as the name suggests.\n",
    "-   `df.melt()` for wide to long.\n",
    "-   `df.pivot()` for long to wide.\n",
    "-   `df.explode()` for breaking strings into rows.\n",
    "-   `df.unstack()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "afebde47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b28e0cc",
   "metadata": {},
   "source": [
    "### Wide to Long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "5f78de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following example is adapted from Pandas documentation: https://Pandas.pydata.org/docs/reference/api/Pandas.wide_to_long.html\n",
    "\n",
    "np.random.seed(123)\n",
    "wide = pl.DataFrame({\n",
    "    'famid': [\"11\", \"12\", \"13\", \"2\", \"2\", \"2\", \"3\", \"3\", \"3\"],\n",
    "    'birth': [1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
    "    'ht1': [2.8, 2.9, 2.2, 2, 1.8, 1.9, 2.2, 2.3, 2.1],\n",
    "    'ht2': [3.4, 3.8, 2.9, 3.2, 2.8, 2.4, 3.3, 3.4, 2.9]})\n",
    "\n",
    "wide.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "fd03ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide.melt(\n",
    "  id_vars=['famid', 'birth'], \n",
    "  value_vars=['ht1', 'ht2'], \n",
    "  variable_name='treatment', \n",
    "  value_name='height').sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2da52b",
   "metadata": {},
   "source": [
    "Break strings into rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "64fe5510",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide.explode(columns=['famid']).limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4dc547",
   "metadata": {},
   "source": [
    "### Long to Wide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "092317f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example adapted from https://stackoverflow.com/questions/5890584/how-to-reshape-data-from-long-to-wide-format\n",
    "\n",
    "long = pl.DataFrame({\n",
    "    'id': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "    'treatment': ['A', 'A', 'B', 'A', 'A', 'B', 'A', 'A', 'B'],\n",
    "    'height': [2.8, 2.9, 2.2, 2, 1.8, 1.9, 2.2, 2.3, 2.1]\n",
    "    })\n",
    "  \n",
    "long.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "98db0bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "long.pivot(\n",
    "  index='id', # index in the wide format\n",
    "  columns='treatment', # defines columns in the wide format\n",
    "  values='height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "8d770c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "long.unstack(step=2) # works like a transpose, and then wrap rows. Change the `step=` to get the feeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c3bd68",
   "metadata": {},
   "source": [
    "## Nested dtypes {#sec-nested-dtypes}\n",
    "\n",
    "\n",
    "\n",
    "## Dataframe in Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "9a1cc1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.estimated_size(unit=\"mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "821ef7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.n_chunks() # number of ChunkedArrays in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "5923b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rechunk() # ensure contiguous memory layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "462add44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shrink_to_fit() # reduce memory allocation to actual size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff2c8f0",
   "metadata": {},
   "source": [
    "## Processing Multiple Frames Simultanously\n",
    "\n",
    "Q: What if you want to access a column from frame `df`, when processing frame `df2`?\\\n",
    "A: Just join them.\\\n",
    "Q: What if they are not joinable?\\\n",
    "A: Use a diagonal join. Q: Can't I just add a search-space into the lazy query? A: Ahhh! Use `df.with_context()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "b97a97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pl.Series(\"blah\", [100,2,3]).to_frame()\n",
    "\n",
    "q = (\n",
    "    df.lazy()\n",
    "    .with_context( # add colums of df2 to the search space\n",
    "        df3.lazy()\n",
    "        )\n",
    "    .with_columns(\n",
    "        pl.col('float').map_dict(remapping={4.0:None}, default=100).fill_null(pl.col('blah').mean()).alias('float2'),\n",
    "        )\n",
    "    )\n",
    "\n",
    "q.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c40a8",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    "-   `with_context()` is a lazy operation. This is great news, since it means both frames will benefit from query planning, etc.\n",
    "-   `with_context()` will not copy the data, but rather, add a reference to the data.\n",
    "-   Why not use `pl.col('blah').mean()` within the `map_dict()`? That is indeed more reasonable. It simply did not work.\n",
    "-   Try it yourself: Can you use multiple `with_context()`?\n",
    "\n",
    "\n",
    "### Imputation Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "202eda52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lf = pl.LazyFrame(\n",
    "    {\"feature_0\": [-1.0, 0, 1], \"feature_1\": [-1.0, 0, 1]}\n",
    ")\n",
    "test_lf = pl.LazyFrame(\n",
    "    {\"feature_0\": [-1.0, None, 1], \"feature_1\": [-1.0, 0, 1]}\n",
    ")\n",
    "\n",
    "(\n",
    "  test_lf\n",
    "  .with_context(\n",
    "    train_lf\n",
    "    .select(pl.all().suffix(\"_train\")))\n",
    "    .select(\n",
    "      pl.col(\"feature_0\")\n",
    "      .fill_null(\n",
    "        pl.col(\"feature_0_train\").median()\n",
    "      )\n",
    "  )\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983ff095",
   "metadata": {},
   "source": [
    "# Polars Expressions {#sec-expressions}\n",
    "\n",
    "Things to recall about Polars expressions:\n",
    "\n",
    "1. Think of them as functions, that can be chained, and evaluated (lazyly) within a Polars context such as `df.select()`, `df.with_columns()`, etc.\n",
    "2. They are not the same as Python functions, and will not work outside of a Polars context.\n",
    "3. Almost all `pl.Series()` methods are available as Polars expressions. There are however some exceptions.\n",
    "\n",
    "\n",
    "Because almost all Polars Series methods are available as Polars expressions, we refer the reader to @sec-series for a review of importanta series methods. \n",
    "In this section we will focus on exceptions, and some important expressions that are not available for Series.\n",
    "\n",
    "\n",
    "## Arithmetic\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Polars LazyFrames\n",
    "\n",
    "# Extensions\n",
    "\n",
    "## SQL\n",
    "\n",
    "## Plotting\n",
    "\n",
    "## ML \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
